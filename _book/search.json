[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cultural Evolution and Music",
    "section": "",
    "text": "On these pages you will learn about cultural evolution and music. The overall aim is to attain a basic understanding of formal models in cultural evolution and learn about several recent approaches that apply them to the domain of music.\nWe first summarize some general ideas about music and cultural evolution. Subsequently, we follow an excellent learning path for computational models in cultural evolution by working through the book Individual-based models of cultural evolution (Acerbi, Mesoudi, and Smolla 2022). Chapters X–Y comprise a translation of this resource to the Python language that we will use throughout. Finally, we will review and discuss a number of recent publications on music and cultural evolution in the advanced topics section.\n\n\n\n\n\n\nNote\n\n\n\nNote that the materials here are still under development. Please inform me if you notice any errors or other issues.\n\n\n\n\n\n\nAcerbi, Alberto, Alex Mesoudi, and Marco Smolla. 2022. Individual-Based Models of Cultural Evolution: A Step-by-Step Guide Using R. London: Routledge. https://acerbialberto.com/IBM-cultevo/."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "The field of cultural evolution emerged in the 1980’s, and has, in parallel with the advancement of computational facilities, gained momentum. In recent years, several approaches have attempted to apply formal models from cultural evolution to the domain of music (Youngblood, Ozaki, and Savage forthcoming).\nIn the present context, we first introduce some central ideas of cultural evolution and review a few major publications for the domain of music.\n\n\n\n\n\n\n\n\n\nYoungblood, Mason, Yuto Ozaki, and Patrick E. Savage. forthcoming. “Cultural Evolution and Music.” In Oxford Handbook of Cultural Evolution, edited by J. Tehrani, J. R. Kendal, and R. L. Kendal. Oxford University Press. https://psyarxiv.com/xsb7v."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "chapter01.html",
    "href": "chapter01.html",
    "title": "3  Unbiased transmission",
    "section": "",
    "text": "Import some modules.\n\nimport numpy as np\nrng = np.random.default_rng()\n\nimport pandas as pd\n\n\nN = 100\nt_max = 100\n\n\npopulation = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)})\npopulation.head()\n\n\n\n\n\n  \n    \n      \n      trait\n    \n  \n  \n    \n      0\n      A\n    \n    \n      1\n      B\n    \n    \n      2\n      B\n    \n    \n      3\n      B\n    \n    \n      4\n      B\n    \n  \n\n\n\n\n\noutput = pd.DataFrame(\n    {\n        \"generation\": np.arange(t_max, dtype=int), \n        \"p\": [np.nan] * t_max \n    }\n)\noutput\n\n\n\n\n\n  \n    \n      \n      generation\n      p\n    \n  \n  \n    \n      0\n      0\n      NaN\n    \n    \n      1\n      1\n      NaN\n    \n    \n      2\n      2\n      NaN\n    \n    \n      3\n      3\n      NaN\n    \n    \n      4\n      4\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      95\n      NaN\n    \n    \n      96\n      96\n      NaN\n    \n    \n      97\n      97\n      NaN\n    \n    \n      98\n      98\n      NaN\n    \n    \n      99\n      99\n      NaN\n    \n  \n\n100 rows × 2 columns\n\n\n\n\noutput.loc[0, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n\nfor t in range(1, t_max):\n    # Copy the population tibble to previous_population tibble\n    previous_population = population.copy()\n  \n    # Randomly copy from previous generation's individuals\n    population = population[\"trait\"].sample(N, replace=True).to_frame()\n    \n    # Get p and put it into the output slot for this generation t\n    output.loc[t, \"p\"] = population[ population[\"trait\"] == \"A\"].shape[0] / N\n\n\noutput\n\n\n\n\n\n  \n    \n      \n      generation\n      p\n    \n  \n  \n    \n      0\n      0\n      0.49\n    \n    \n      1\n      1\n      0.58\n    \n    \n      2\n      2\n      0.62\n    \n    \n      3\n      3\n      0.62\n    \n    \n      4\n      4\n      0.70\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      95\n      1.00\n    \n    \n      96\n      96\n      1.00\n    \n    \n      97\n      97\n      1.00\n    \n    \n      98\n      98\n      1.00\n    \n    \n      99\n      99\n      1.00\n    \n  \n\n100 rows × 2 columns\n\n\n\n\ndef unbiased_transmission_1(N, t_max):\n    population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)})\n    output = pd.DataFrame({\"generation\": np.arange(t_max, dtype=int), \"p\": [np.nan] * t_max })\n    output.loc[0, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    for t in range(1, t_max):\n        # Copy the population tibble to previous_population tibble\n        previous_population = population.copy()\n    \n        # Randomly copy from previous generation's individuals\n        population = population[\"trait\"].sample(N, replace=True).to_frame()\n        \n        # Get p and put it into the output slot for this generation t\n        output.loc[t, \"p\"] = population[ population[\"trait\"] == \"A\"].shape[0] / N\n    \n    return output\n\n\ndata_model = unbiased_transmission_1(N=100, t_max=200)\n\n\ndef plot_single_run(data_model):\n    data_model[\"p\"].plot(ylim=(0,1))\n\n\nplot_single_run(data_model)\n\n\n\n\nSingle run of the unbiased transmission model for a population of \\(N=100\\) individuals and \\(t_{max}=200\\) generations.\n\n\n\n\n\ndata_model = unbiased_transmission_1(N=10_000, t_max=200)\n\n\nplot_single_run(data_model)\n\n\n\n\nSingle run of the unbiased transmission model for a population of \\(N=10,000\\) individuals and \\(t_{max}=200\\) generations.\n\n\n\n\n\ndef unbiased_transmission_2(N, t_max, r_max):\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population.copy()\n\n            # Randomly compy from previous generation \n            population = population[\"trait\"].sample(N, replace=True).to_frame()\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output\n\n\nunbiased_transmission_2(100, 100, 3)\n\n\n\n\n\n  \n    \n      \n      generation\n      p\n      run\n    \n  \n  \n    \n      0\n      0\n      0.57\n      0\n    \n    \n      1\n      1\n      0.58\n      0\n    \n    \n      2\n      2\n      0.54\n      0\n    \n    \n      3\n      3\n      0.54\n      0\n    \n    \n      4\n      4\n      0.43\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      295\n      95\n      0.00\n      2\n    \n    \n      296\n      96\n      0.00\n      2\n    \n    \n      297\n      97\n      0.00\n      2\n    \n    \n      298\n      98\n      0.00\n      2\n    \n    \n      299\n      99\n      0.00\n      2\n    \n  \n\n300 rows × 3 columns\n\n\n\n\ndata_model = unbiased_transmission_2(N=100, t_max=200, r_max=5)\n\n\ndef plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n\n\nplot_multiple_runs(data_model)\n\n\n\n\nMultiple runs of the unbiased transmission model for a population of \\(N=100\\) individuals, with average (black line).\n\n\n\n\n\ndata_model = unbiased_transmission_2(N=10_000, t_max=200, r_max=5)\n\n\nplot_multiple_runs(data_model)\n\n\n\n\nMultiple runs of the unbiased transmission model for a population of \\(N=10,000\\) individuals, with average (black line).\n\n\n\n\n\ndef unbiased_transmission_3(N, p_0, t_max, r_max):\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population\n\n            # Randomly compy from previous generation \n            population = population[\"trait\"].sample(N, replace=True).to_frame()\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output\n\n\ndata_model = unbiased_transmission_3(10_000, p_0=.2, t_max=200, r_max=5)\nplot_multiple_runs(data_model)\n\n\n\n\n\n\n\n\nAcerbi, Alberto, Alex Mesoudi, and Marco Smolla. 2022. Individual-Based Models of Cultural Evolution: A Step-by-Step Guide Using R. London: Routledge. https://acerbialberto.com/IBM-cultevo/."
  },
  {
    "objectID": "chapter02.html",
    "href": "chapter02.html",
    "title": "4  Unbiased and biased mutation",
    "section": "",
    "text": "def unbiased_mutation(N, mu, p_0, t_max, r_max):\n    # Create an output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population.copy()\n            \n            # Determine \"mutant\" individuals\n            mutate = rng.choice([True, False], size=N, p=[mu, 1-mu], replace=True)\n\n            # TODO: Something is off here! Changing the order of the conditions affects\n            # the result. Should be constant with random noise but converges to either A or B\n\n            # If there are \"mutants\" from A to B \n            conditionA = mutate & (previous_population[\"trait\"] == \"A\")\n            if conditionA.sum() > 0:\n                population.loc[conditionA, \"trait\"] = \"B\"\n\n            # If there are \"mutants\" from B to A\n            conditionB = mutate & (previous_population[\"trait\"] == \"B\")\n            if conditionB.sum() > 0:\n                population.loc[conditionB, \"trait\"] = \"A\"\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output \n\n\ndef plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n\n\ndata_model = unbiased_mutation(N=100, mu=.05, p_0=0.5, t_max=200, r_max=5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model = unbiased_mutation(N=100, mu=.05, p_0=0.1, t_max=200, r_max=5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndef biased_mutation(N, mu_b, p_0, t_max, r_max):\n    # Create the output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population.copy()\n            \n            # Determine \"mutant\" individuals\n            mutate = rng.choice([True, False], size=N, p=[mu_b, 1-mu_b], replace=True)\n\n            # TODO: Something is off here! Changing the order of the conditions affects\n            # the result. Should be constant with random noise but converges to either A or B\n\n            # If there are \"mutants\" from B to A\n            conditionB = mutate & (previous_population[\"trait\"] == \"B\")\n            if conditionB.sum() > 0:\n                population.loc[conditionB, \"trait\"] = \"A\"\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output \n\n\ndata_model = biased_mutation(N = 100, mu_b = 0.05, p_0 = 0, t_max = 200, r_max = 5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model = biased_mutation(N = 10000, mu_b = 0.05, p_0 = 0, t_max = 200, r_max = 5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model <- biased_mutation(N = 10000, mu_b = 0.1, p_0 = 0, t_max = 200, r_max = 5)\nplot_multiple_runs(data_model)"
  },
  {
    "objectID": "chapter03.html",
    "href": "chapter03.html",
    "title": "5  Biased transmission: direct bias",
    "section": "",
    "text": "def plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n\n\ndef biased_transmission_direct(N, s_a, s_b, p_0, t_max, r_max):\n    # Create the output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population.copy()\n\n            # For each individual, pick a random individual from the previous generation\n            demonstrator_trait = previous_population[\"trait\"].sample(N, replace=True).reset_index()\n            \n            # Biased probabilities to copy\n            copy_a = rng.choice([True, False], size=N, replace=True, p=[s_a, 1 - s_a])\n            copy_b = rng.choice([True, False], size=N, replace=True, p=[s_b, 1 - s_b])\n\n            # If the demonstrator has trait A and the individual wants to copy A, then copy A\n            condition = copy_a & (demonstrator_trait[\"trait\"] == \"A\")\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"A\"\n\n            # If the demonstrator has trait B and the individual wants to copy B, then copy B\n            condition = copy_b & (demonstrator_trait[\"trait\"] == \"B\")\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"B\"\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output \n\n\ndata_model = biased_transmission_direct(N=10_000, s_a=.1, s_b=0, \n                                         p_0=.01, t_max=200, r_max=5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model = biased_transmission_direct(N=10_000, s_a=.6, s_b=.5, \n                                         p_0=.01, t_max=150, r_max=5)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model = biased_transmission_direct(N=10_000, s_a=.2, s_b=0, \n                                         p_0=.01, t_max=200, r_max=5)\nplot_multiple_runs(data_model)"
  },
  {
    "objectID": "chapter04.html",
    "href": "chapter04.html",
    "title": "6  Biased transmission: frequency-dependent indirect bias",
    "section": "",
    "text": "def plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n\n\nN = 100\np_0 = .5\nD = 1.\n\n\n# Create first generation\npopulation = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1-p_0])})\n\n\n# Create a DataFrame with a set of 3 randomly-picked demonstrators for each agent\n\ndemonstrators = pd.DataFrame({\n    \"dem1\" : population[\"trait\"].sample(N, replace=True).values,\n    \"dem2\" : population[\"trait\"].sample(N, replace=True).values,\n    \"dem3\" : population[\"trait\"].sample(N, replace=True).values\n})\n\n\n# Visualize the DataFrame\ndemonstrators\n\n\n\n\n\n  \n    \n      \n      dem1\n      dem2\n      dem3\n    \n  \n  \n    \n      0\n      A\n      A\n      B\n    \n    \n      1\n      A\n      B\n      B\n    \n    \n      2\n      A\n      A\n      A\n    \n    \n      3\n      A\n      B\n      A\n    \n    \n      4\n      B\n      A\n      B\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      A\n      B\n      B\n    \n    \n      96\n      B\n      B\n      B\n    \n    \n      97\n      B\n      A\n      B\n    \n    \n      98\n      A\n      B\n      A\n    \n    \n      99\n      B\n      B\n      A\n    \n  \n\n100 rows × 3 columns\n\n\n\n\n# Get the number of A's in each 3-demonstrator combination\nnum_As = (demonstrators == \"A\").apply(sum, axis=1)\nnum_As\n\n0     2\n1     1\n2     3\n3     2\n4     1\n     ..\n95    1\n96    0\n97    1\n98    2\n99    1\nLength: 100, dtype: int64\n\n\n\n# For 3-demonstrator combinations with all A's, set to A\npopulation[ num_As == 3 ] = \"A\"\n# For 3-demonstrator combinations with all B's, set to B\npopulation[ num_As == 0 ] = \"B\"\n\n\nprob_majority = rng.choice([True, False], p=[(2/3 + D/3), 1-(2/3 + D/3)], size=N, replace=True)\nprob_minority = rng.choice([True, False], p=[(1/3 + D/3), 1-(1/3 + D/3)], size=N, replace=True)\n\n\n# 3-demonstrator combinations with two As and one B\ncondition = prob_majority & (num_As == 2)\nif condition.sum() > 0:\n    population.loc[condition, \"trait\"] = \"A\"\ncondition = ~prob_majority & (num_As == 2)\nif condition.sum() > 0:\n    population.loc[condition, \"trait\"] = \"B\"\n\n# 3-demonstrator combinations with two B's and one A\ncondition = ~prob_minority & (num_As == 1)\nif condition.sum() > 0:\n    population.loc[condition, \"trait\"] = \"A\"\ncondition = prob_minority & (num_As == 1)\nif condition.sum() > 0:\n    population.loc[condition, \"trait\"] = \"B\"\n\n\ndemonstrators[\"new_trait\"] = population[\"trait\"]\ndemonstrators\n\n\n\n\n\n  \n    \n      \n      dem1\n      dem2\n      dem3\n      new_trait\n    \n  \n  \n    \n      0\n      A\n      A\n      B\n      A\n    \n    \n      1\n      A\n      B\n      B\n      B\n    \n    \n      2\n      A\n      A\n      A\n      A\n    \n    \n      3\n      A\n      B\n      A\n      A\n    \n    \n      4\n      B\n      A\n      B\n      A\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      A\n      B\n      B\n      B\n    \n    \n      96\n      B\n      B\n      B\n      B\n    \n    \n      97\n      B\n      A\n      B\n      A\n    \n    \n      98\n      A\n      B\n      A\n      A\n    \n    \n      99\n      B\n      B\n      A\n      B\n    \n  \n\n100 rows × 4 columns\n\n\n\n\ndef conformist_transmission(N, p_0, D, t_max, r_max):\n    # Create the output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            demonstrators = pd.DataFrame({\n                \"dem1\" : population[\"trait\"].sample(N, replace=True).values,\n                \"dem2\" : population[\"trait\"].sample(N, replace=True).values,\n                \"dem3\" : population[\"trait\"].sample(N, replace=True).values\n            })\n\n            # Get the number of A's in each 3-demonstrator combination\n            num_As = (demonstrators == \"A\").apply(sum, axis=1)\n\n            # For 3-demonstrator combinations with all A's, set to A\n            population[ num_As == 3 ] = \"A\"\n            # For 3-demonstrator combinations with all A's, set to A\n            population[ num_As == 3 ] = \"A\"\n            # For 3-demonstrator combinations with all B's, set to B\n            population[ num_As == 0 ] = \"B\"\n\n            prob_majority = rng.choice([True, False], p=[(2/3 + D/3), 1-(2/3 + D/3)], size=N, replace=True)\n            prob_minority = rng.choice([True, False], p=[(1/3 + D/3), 1-(1/3 + D/3)], size=N, replace=True)\n\n            # 3-demonstrator combinations with two As and one B\n            condition = prob_majority & (num_As == 2)\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"A\"\n            condition = ~prob_majority & (num_As == 2)\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"B\"\n\n            # 3-demonstrator combinations with two B's and one A\n            condition = prob_minority & (num_As == 1)\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"A\"\n            condition = ~prob_minority & (num_As == 1)\n            if condition.sum() > 0:\n                population.loc[condition, \"trait\"] = \"B\"\n            \n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output\n\n\ndata_model = conformist_transmission(N=1_000, p_0 = 0.5, D = 1, t_max = 50, r_max = 10)\nplot_multiple_runs(data_model)"
  },
  {
    "objectID": "chapter05.html",
    "href": "chapter05.html",
    "title": "7  Biased transmission: demonstrator-based indirect bias",
    "section": "",
    "text": "def plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n\n\nN = 100\np_0 = 0.5\np_s = 0.05\n\n\npopulation = pd.DataFrame({\n    \"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1-p_0]),\n    \"status\": rng.choice([\"high\", \"low\"], size=N, replace=True, p=[p_s, 1-p_s])\n})\n\n\npopulation\n\n\n\n\n\n  \n    \n      \n      trait\n      status\n    \n  \n  \n    \n      0\n      B\n      low\n    \n    \n      1\n      A\n      low\n    \n    \n      2\n      A\n      low\n    \n    \n      3\n      B\n      low\n    \n    \n      4\n      A\n      low\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      A\n      low\n    \n    \n      96\n      B\n      low\n    \n    \n      97\n      A\n      low\n    \n    \n      98\n      B\n      low\n    \n    \n      99\n      B\n      low\n    \n  \n\n100 rows × 2 columns\n\n\n\n\np_low = 0.01\np_demonstrator = np.ones(N)\np_demonstrator[ population[\"status\"] == \"low\" ] = p_low\n\n\nif sum(p_demonstrator) > 0:\n    ps = p_demonstrator / p_demonstrator.sum()\n    demonstrator_index = rng.choice(np.arange(N), size=N, p=ps, replace=True)\n    population[\"trait\"] = population.loc[demonstrator_index, \"trait\"].values\n\n\ndef biased_transmission_demonstrator(N, p_0, p_s, p_low, t_max, r_max):\n    # Create the output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n    \n    for r in range(r_max):\n            # Create first generation\n            population = pd.DataFrame({\n                \"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1-p_0]),\n                \"status\": rng.choice([\"high\", \"low\"], size=N, replace=True, p=[p_s, 1-p_s])\n            })\n            \n            # Assign copying probabilities based on individuals' status\n            p_demonstrator = np.ones(N)\n            p_demonstrator[population[\"status\"] == \"low\"] = p_low\n            \n            # Add first generation's p for run r\n            output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n            \n            for t in range(1, t_max):\n                # Copy individuals to previous_population DataFrame\n                previous_population = population.copy()\n                \n                # Copy traits based on status\n                if sum(p_demonstrator) > 0:\n                    ps = p_demonstrator / p_demonstrator.sum()\n                    demonstrator_index = rng.choice(np.arange(N), size=N, p=ps, replace=True)\n                    population[\"trait\"] = population.loc[demonstrator_index, \"trait\"].values\n                \n                # Get p and put it into output slot for this generation t and run r\n                output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n                \n    return output\n\n\ndata_model = biased_transmission_demonstrator(N=100, p_s=0.05, p_low=0.0001, p_0=0.5, t_max=50, r_max=10)\n\n\nplot_multiple_runs(data_model)\n\n\n\n\n\ndata_model = biased_transmission_demonstrator(N=10_000, p_s=0.005, p_low=0.0001, p_0=0.5, t_max=200, r_max=10)\nplot_multiple_runs(data_model)\n\n\n\n\n\ndef biased_transmission_demonstrator_2(N, p_0, p_s, p_low, t_max, r_max):\n    # Create the output DataFrame\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n    \n    ...\n    \n    return output\n\n\ndata_model = biased_transmission_demonstrator_2(N=100, p_s=0.1, p_low=0.0001, p_0=0.5, t_max=50, r_max=50)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acerbi, Alberto, Alex Mesoudi, and Marco Smolla. 2022.\nIndividual-Based Models of Cultural Evolution: A Step-by-Step Guide\nUsing R. London: Routledge. https://acerbialberto.com/IBM-cultevo/.\n\n\nMoss, Fabian C., Markus Neuwirth, and Martin Rohrmeier. 2022. “The\nLine of Fifths and the Co-Evolution of Tonal Pitch-Classes.”\nJournal of Mathematics and Music, 1–25. https://doi.org/10.1080/17459737.2022.2044927.\n\n\nNakamura, Eita, and Kunihiko Kaneko. 2019. “Statistical\nEvolutionary Laws in Music Styles.” Nature Scientific\nReports 9 (1): 15993. https://doi.org/10.1038/s41598-019-52380-6.\n\n\nSavage, Patrick E. 2019. “Cultural Evolution of Music.”\nPalgrave Communications 5 (1): 1–16. https://doi.org/10.1057/s41599-019-0221-1.\n\n\nStreet, Sally, Tuomas Eerola, and Jeremy R. Kendal. 2022. “The\nRole of Population Size in Folk Tune Complexity.” Humanities\nand Social Sciences Communications 9 (1): 1–12. https://doi.org/10.1057/s41599-022-01139-y.\n\n\nYoungblood, Mason, Yuto Ozaki, and Patrick E. Savage. forthcoming.\n“Cultural Evolution and Music.” In Oxford Handbook of\nCultural Evolution, edited by J. Tehrani, J. R. Kendal, and R. L.\nKendal. Oxford University Press. https://psyarxiv.com/xsb7v."
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "8  Advanced topics",
    "section": "",
    "text": "“Cultural Evolution of Music” (Savage 2019)\n“The role of population size in folk tune complexity” (Street, Eerola, and Kendal 2022)\n“Statistical Evolutionary Laws in Music Styles” (Nakamura and Kaneko 2019)\n“The line of fifths and the co-evolution of tonal pitch-classes” (Moss, Neuwirth, and Rohrmeier 2022)\n“” (Youngblood, Ozaki, and Savage)\n\n\n\n\n\nMoss, Fabian C., Markus Neuwirth, and Martin Rohrmeier. 2022. “The Line of Fifths and the Co-Evolution of Tonal Pitch-Classes.” Journal of Mathematics and Music, 1–25. https://doi.org/10.1080/17459737.2022.2044927.\n\n\nNakamura, Eita, and Kunihiko Kaneko. 2019. “Statistical Evolutionary Laws in Music Styles.” Nature Scientific Reports 9 (1): 15993. https://doi.org/10.1038/s41598-019-52380-6.\n\n\nSavage, Patrick E. 2019. “Cultural Evolution of Music.” Palgrave Communications 5 (1): 1–16. https://doi.org/10.1057/s41599-019-0221-1.\n\n\nStreet, Sally, Tuomas Eerola, and Jeremy R. Kendal. 2022. “The Role of Population Size in Folk Tune Complexity.” Humanities and Social Sciences Communications 9 (1): 1–12. https://doi.org/10.1057/s41599-022-01139-y.\n\n\nYoungblood, Mason, Yuto Ozaki, and Patrick E. Savage. In Oxford Handbook of Cultural Evolution, edited by J. Tehrani, J. R. Kendal, and R. L. Kendal. Oxford University Press."
  },
  {
    "objectID": "advanced.html#savage-2019",
    "href": "advanced.html#savage-2019",
    "title": "8  title: Advanced topics",
    "section": "8.1 Savage (2019)",
    "text": "8.1 Savage (2019)\n(Savage 2019)\n\n\n\n\nSavage, Patrick E. 2019. “Cultural Evolution of Music.” Palgrave Communications 5 (1). https://doi.org/10.1057/s41599-019-0221-1."
  },
  {
    "objectID": "intro.html#section",
    "href": "intro.html#section",
    "title": "1  Introduction: The Cultural Evolution of Music",
    "section": "1.1 ",
    "text": "1.1 \n\n\n\n\nAcerbi, Alberto, Alex Mesoudi, and Marco Smolla. 2022. Individual-Based Models of Cultural Evolution: A Step-by-Step Guide Using R. London: Routledge. https://acerbialberto.com/IBM-cultevo/."
  },
  {
    "objectID": "intro.html#the-cultural-evolution-of-music",
    "href": "intro.html#the-cultural-evolution-of-music",
    "title": "1  Introduction",
    "section": "1.1 The Cultural Evolution of Music",
    "text": "1.1 The Cultural Evolution of Music\nThe field of cultural evolution emerged in the 1980’s, and has, in parallel with the advancement of computational facilities, gained momentum. In recent years, several approaches have attempted to apply formal models from cultural evolution to the domain of music (Youngblood, Ozaki, and Savage forthcoming).\nIn the present context, we first introduce some central ideas of cultural evolution and review a few major publications for the domain of music.\n\n1.1.1 Central ideas\n\n\n1.1.2 Cultural evolution in music research\n\n\n\n\nAcerbi, Alberto, Alex Mesoudi, and Marco Smolla. 2022. Individual-Based Models of Cultural Evolution: A Step-by-Step Guide Using R. London: Routledge. https://acerbialberto.com/IBM-cultevo/.\n\n\nYoungblood, Mason, Yuto Ozaki, and Patrick E. Savage. forthcoming. “Cultural Evolution and Music.” In Oxford Handbook of Cultural Evolution, edited by J. Tehrani, J. R. Kendal, and R. L. Kendal. Oxford University Press. https://psyarxiv.com/xsb7v."
  },
  {
    "objectID": "chapter00.html",
    "href": "chapter00.html",
    "title": "2  A Python primer",
    "section": "",
    "text": "Variable assignment in Python is straight-forward. You choose a name for the variable, and assign a value to it using the = operator, for example:\n\nx = 100\n\nassigns the value 100 to the variable x. If we call the variable now, we can see that it has the value we assigned to it:\n\nx\n\n100\n\n\nOf course, we can also assign things other than numbers, for example:\n\nname = \"Fabian\"\n\nWhat we assigned to the variable name is called a string, it has the value \"Fabian\". Strings are sequences of characters.\n\n\n\n\n\n\nTip\n\n\n\nNote that \"Fabian\" is enclosed by double-quotes. Why is this the case? Why could we not just type name = Fabian?\n\n\nWe can also assign a list of things to a variable:\n\nmylist = [1, 2, 3, \"A\", \"B\", \"C\"]\n\nLists are enclosed by square brackets. As you can see, Python allows you to store any kind of data in lists (here: integer numbers and character strings). However, it is good practice to include only—you’ll understand later why."
  },
  {
    "objectID": "chapter00.html#data-types",
    "href": "chapter00.html#data-types",
    "title": "2  A Python primer",
    "section": "2.2 Data types",
    "text": "2.2 Data types"
  },
  {
    "objectID": "chapter00.html#loops",
    "href": "chapter00.html#loops",
    "title": "2  A Python primer",
    "section": "2.2 Loops",
    "text": "2.2 Loops"
  },
  {
    "objectID": "chapter00.html#libraries-youll-love",
    "href": "chapter00.html#libraries-youll-love",
    "title": "2  A Python primer",
    "section": "2.4 Libraries you’ll love",
    "text": "2.4 Libraries you’ll love\nLuckily, you don’t have to programm all functions by yourself. There is a huge community of Python programmers out there that works and collaborates on several libraries. A library is (more or less) simply a collection of certain functions (and some more, but we don’t get into this here). This means, instead of writing a function yourself, you can rely on functions that someone else has programmed.\n\n\n\n\n\n\nDanger\n\n\n\nWhether a Python library or function does actually do what it promises is another story. Popular libraries with tens of thousands of users are very trust-worthy because you can be almost sure that someone would have noticed erroneous behavior. But it is certainly possible that badly-maintained libraries contain errors. So be prudent when using the code of others.\n\n\nOne of the most popular Python libaries is NumPy for numerical computations. We will rely a lot on the functions in this library, especially in order to draw random samples—more on this later! To use the functions or variables from this library, they have to be imported so that you can use them. There are several ways to do this. For example, you can import the libary entirely:\n\nimport numpy\n\nNow, you can use the (approximated) value of \\(\\pi\\) stored in this library by typing\n\nnumpy.pi\n\n3.141592653589793\n\n\nA different way is to just import everything from the library by writing\n\nfrom numpy import * \n\nHere, the * stands for ‘everything’. Now, to use the value of \\(\\pi\\) we could simply type\n\npi\n\n3.141592653589793\n\n\nThis is, however discouraged for the following reason: imagine we had another library, numpy2 that also stores the value of \\(\\pi\\), but less precisely (e.g. only as 3.14). If we write\n\nfrom numpy import * \nfrom numpy2 import * \n\nWe would have imported the variables holding the value of \\(\\pi\\) from both libraries. But, because they have the same name pi. In this case, pi would equal 3.14 because we imported numpy2 last. This is confusing and shouldn’t be so! To avoid this, it is better to keep references to imported libraries explicit. In order not to have to type too much (we’re all lazy, after all), we can define an alias for the library.\n\nimport numpy as np\nnp.pi\n\n3.141592653589793\n\n\nAll functions of NumPy are now accessible with the prefix np.. You can choose any alias when importing a library (it can even by longer than the library name) but certain conventions have emerged that you’re encouraged to follow. Importing the most commonly used Python libraries for data-science tasks (“The data science triad”), use the following:\n\nimport numpy as np # for numerical computations\nimport pandas as pd # for tabular data \nimport matplotlib.pyplot as plt # for data visualization\n\nWe will use all three of them in the following chapters."
  },
  {
    "objectID": "chapter00.html#repeating-stuff",
    "href": "chapter00.html#repeating-stuff",
    "title": "2  A Python primer",
    "section": "2.2 Repeating stuff",
    "text": "2.2 Repeating stuff"
  },
  {
    "objectID": "chapter00.html#repeating-thigns",
    "href": "chapter00.html#repeating-thigns",
    "title": "2  A Python primer",
    "section": "2.2 Repeating thigns",
    "text": "2.2 Repeating thigns"
  },
  {
    "objectID": "chapter00.html#on-repeat",
    "href": "chapter00.html#on-repeat",
    "title": "2  A Python primer",
    "section": "2.2 On repeat",
    "text": "2.2 On repeat\nCoding something is only useful if you can’t do the job as fast or as efficient by yourself. Especially when it comes to repeating the same little thing many, many times, knowing how to code comes in handy.\nAs a simple example, imagine you want to write down all numbers from 1 to 10, or from 1 to 100, or… you get the idea. In Python, you would do it as follows:\n\nfor i in range(10):\n    print(i)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nYou see that this is not exactly what we wanted. We’re seeing numbers from 0 to 9, but we wanted everything from 1 to 10. Before we fix the code to produce the desired result, let’s explain the bits and pieces of the code above. What we just did was to use a so-called for-loop, probably the most common way to repeat things in Python. First we create an iterator variable i (we could have named any other variable name as well), which takes its value from the list of numbers specified by range(10). If only one number n is provided to range(n), it will enumerate all numbers from 0 to n-1. If two arguments are provided, the first one determines the starting number, and the second one stands for the terminating number minus one—confusing, right? So, in order to enumerate all numbers from 1 to 10, we have to write range(1,11). Finally, the print function outputs the value of i for each iteration.\n\nfor i in range(1,11):\n    print(i)\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nVoilà!"
  },
  {
    "objectID": "chapter00.html#functions-and-abstactions",
    "href": "chapter00.html#functions-and-abstactions",
    "title": "2  A Python primer",
    "section": "2.3 Functions and abstactions",
    "text": "2.3 Functions and abstactions\nWith more and more experience in programming, it is likely that your code will become more and more complex. That means that it will become harder to keep track of what every piece of it is supposed to do. A good strategy to deal with this is to aim for writing code that is modular: it can be broken down into smaller units (modules) that are easier to understand. Moreover, it is sometimes necessary to reuse the same code several times. It would, however, be inefficient to write the same lines over and over again. With your code being modular you can wrap the pieces that you need in several places into a function.\nLet’s look at an example! Assume, your (fairly) complex code involves calculating the sum of the products of two numbers. In Python, we use the + operator to calculate sums and the ** operator to raise a number to a certain power (**2 for the square of a number).\n\nx = 3\ny = 5\n\nsum_of_squares = x**2 + y**2\n\nThe variable sum_of_squares now contains the sum of squares of x=3 and y=5. We can inspect the result by calling the variable:\n\nsum_of_squares \n\n34\n\n\nNow, imagine that you would have to do the same calculation several times for different combinations of values for x and y (and always keeping in mind that this stands in for much more complex examples with several lines of code). We can this code in a function:\n\ndef func_sum_of_squares(x, y):\n    return x**2 + y**2\n\nNow, each time we want to calculate a sum of squares, we can do so by simply invoking\n\nfunc_sum_of_squares(5,4)\n\n41\n\n\nAnd, of course, we could chose a shorter name for the function as well:\n\nf = func_sum_of_squares\n\nf(5,4)\n\n41"
  }
]