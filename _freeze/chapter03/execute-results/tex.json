{
  "hash": "310ce567c9dd0a5c5e0cf0995deb946d",
  "result": {
    "markdown": "---\nsubtitle: What happens if people just blindly copy?\nfilters:\n  - shinylive\n---\n\n# Unbiased transmission {#sec-unbiased_transmission}\n\n:::{.callout-note}\nThis chapter is based on \"Chapter 1: Unbiased transmission\" in @Acerbi2022.\n:::\n\nIn this chapter, we introduce the most basic model for cultural inheritance: unbiased transmission. This process quite literally corresponds to randomly copying traits from previous generations, without any further distinctions and constraints. While this is obviously a too reductive model for how cultural transmission works, it is ideally suited to get us started with the enterprise of modeling evolutionary processes involving random variation.\n\nFirst we import some modules.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n```\n:::\n\n\nBecause we will model evolutionary processes that are not strictly deterministic, we need to simulate variations due to random change.\nFor this, we can use the _default random number generator_ from the NumPy library and store it in the variable `rng`. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed=42)\n```\n:::\n\n\nNext, we define some basic variables that we take into account for our first model. We consider a population of $N=100$ individuals as well as a time-frame of $t_{max}=100$ generations. \n\n## Creating a conceptual understanding\n\nIt is a useful exercise to imagine first what we want to implement. \nThis way we can check whether we have a good conceptual understanding, which \nwill help us to write the code more clearly and make fewer mistakes.\nThe following figure shows in the upper panel a scenario, in which there is a population of X individuals present in each generation. Those individuals are uniquely characterized by one of two traits: whether they like opera (salmon color) or not (grey).\nThis visualization captures all assumptions we make for our first model:\n\n1. The number of individuals per generation does not change. \n2. Generations are disjunct, there is no overlap.\n3. In the first generation, opera preference is randomly assigned to individuals.\n4. In each subsequent generation, each individual randomly picks an 'ancestor' \n   from the previous generation and blindly copies that individual's preference for opera.\n\n![A conceptual depiction of unbiased transmission.](img/chains.png)\n\nThe lower plot shows, at each time, point the percentage of individuals \nhaving a preference for opera. A logical consequence of this process is that each transmission chain (each sequence of directly connected arrows) will pass through one and only one trait (color).\n\nWe can make further observations from this initial example.\nIn the first generation, there are two individuals who do like opera \nand three who don't. In subsequent generations, the proporation of these \ntwo traits changes. It is not _monotonic_ (it goes both up and down), as the \nred line shows. But in the sixth generation, everything changes.\nIndividuals in the sixth generation _could_ inherit their trait \nfrom the one individual in generation 5 that likes opera. But because \nthey randomly pick their ancestors, that individual is not among the ancestors.\nConsequently, no individual in generation 6 likes opera. \nThis also means that, from now on, now one will ever like opera again. \nOpera fans have become extinct.\n\nWe can see that transmission of information is still going on:\nthere are arrows between generations, so individuals still receive \ninformation from the previous generation. But nothing changes. \nThat means that we _do have_ transmission of information, but we would not \nanymore speak of it as _cultural evolution_, since the first fundamental criterion (see Chapter X), variation, is not fulfilled.\n\nNote also, that some 'traditions' are likewise not continued.\nFor example, following the transmission chain of individual 0 \nin the first generation to individual 2 in the second generation\nto individual 3 in the third generation, we see that this latter \nindividual is not picked as an ancestor by anyone from the next generation.\nThis individual (and all of its ancestors) have no more impact on \nfuture generations. Importantly, however, we are not interested \nin individual fates, but rather in population-level statistics.\nThat is why the lower plot only traces the proportion of individuals \nhaving a preference for opera. \n\n## Simulating a population\n\nWith this conceptual understanding in mind,\nwe will now look at how we can reproduce \nthis model of unbiased transmission. \nSince we are assuming that new individuals \nrandomly pick an ancestor, we should not assume that \nour results will be exactly the same as above,\nbut they should nonetheless be qualitatively similar.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nN = 100\nt_max = 100\n```\n:::\n\n\n:::{.callout-note}\nIn general, we use the variable `t` to designate generation counts. \n:::\n\nNow we create a variable `population` that will store the data about our simulated population. This population has either of two traits `\"A\"` and `\"B\"`, with a certain probability. We store all of this in a so-called 'data frame', which is a somewhat fancy, Pandas-specific term for a table. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\npopulation = pd.DataFrame(\n    {\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)}\n)\n```\n:::\n\n\nLet's take this code apart to understand it better.\nFrom the Pandas library, which we imported as the alias `pd`, we create a `DataFrame` object. The data contained in this the data frame `population` is specified via a dictionary that has `\"trait\"` as its key and a fairly complex expression starting with the random number generator `rng` as its value. What this value says is, from the list `[\"A\", \"B\"]` choose randomly `N` instances with replacement (if `replace` were set to `False`, we could at most sample 2 values from the list). So, the data frame `population` should contain 100 randomly sampled values of A's and B's. Let's confirm this:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\npopulation.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & trait \\\\\n\\midrule\n0 &     A \\\\\n1 &     B \\\\\n2 &     B \\\\\n3 &     A \\\\\n4 &     A \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nAs you can see, `population` stores a table (many of the 100 rows are omitted here for display reasons) and a single column called 'trait'. The `.head()` method appended to the `population` data frame shows restricts the output to only the first 5 rows (0 through 4). Each row in the 'trait' column contains either the value A or B. To the left of the data frame you can see the numbers of rows explicitly spelled out. This is called the data frame's _index_. \n\n:::{.callout-note}\nA and B are just placeholder names for any of two mutually exclusive cultural traits. These could be, for example, preference for red over white whine (ignoring people who like ros√© as well as people who have no preference). You see already here that this is a massive oversimplification of actual taste preferences. The point here is not to construct a plausible model but rather to gradually build up a simple one in order to understand well its inner workings.\n\nIt will help to pause for a moment and to think of other examples that \"A\" and \"B\" could stand for. Can you come up with a music-related one?\n:::\n\nFor instance, we could say that the mutually exclusive\ntraits \"A\" and \"B\" correspond to \"Individual likes opera\" and \"Individual doesn't like opera\". \nPeople are often opinionated about opera, so we \nwill stick to this example for the remainder of \nthis part of the book. But be encouraged to try \nto transfer the following to different hypothetical \nscenarios. \n\n![Scene from [\"What's opera, doc?\"](https://en.wikipedia.org/wiki/What%27s_Opera,_Doc) (1957).](img/opera.jpeg)\n\nBack to our artificial population.\nWe can count the number of A's and B's amongst\nthe individuals as follows:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\npopulation[\"trait\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=tex}\n\\begin{tabular}{lr}\n\\toprule\n{} &  trait \\\\\n\\midrule\nB &     52 \\\\\nA &     48 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nYou can read the above code as \"From the population table, select the 'trait' colum and count its values.\". Since there were only two values to sample from and they were randomly (uniformly) sampled, the number of A's and the number of B's should be approximately equal. We can obtain their relative frequencies by adding setting the `normalize` keyword to `True`:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\npopulation[\"trait\"].value_counts(normalize=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=tex}\n\\begin{tabular}{lr}\n\\toprule\n{} &  trait \\\\\n\\midrule\nB &   0.52 \\\\\nA &   0.48 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\n## Tracing cultural change\n\nWe now create a second data frame `output` in which we will store the output of our model. This data frame has two columns: `generation`, which is the number of the simulated generation, and `p` which stands for \"the probability of an individual of having trait A\".\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\noutput = pd.DataFrame(\n    {\n        \"generation\": np.arange(t_max, dtype=int), \n        \"p\": [np.nan] * t_max \n    }\n)\n```\n:::\n\n\nThe `generation` column contains all numbers from `0` to `t_max - 1`. Because we count the numbers of generations (rather than assuming a time-continuous process), we specified that numbers in this column have to be intergers (`dtype=int`). The values for the `p` column must look cryptic. It literally says: put the `np.nan` value `t_max` times into the `p` colum. `np.nan` stands for \"not a number\" (from the NumPy library), since we haven't assigned any values to this probability yet. \n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\noutput.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=tex}\n\\begin{tabular}{lrr}\n\\toprule\n{} &  generation &   p \\\\\n\\midrule\n0 &           0 & NaN \\\\\n1 &           1 & NaN \\\\\n2 &           2 & NaN \\\\\n3 &           3 & NaN \\\\\n4 &           4 & NaN \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nDon't worry that both the index and the 'generation' column contain all numbers from 0 to 99. We need this later when things become more involved.\n\nAs the saying goes, from nothing comes nothing, so we have to start somewhere, meaning that we need to assume that the initial probability of having trait A in our population is an actual number. The most sensible thing is to start with the proportions of A and B in our sampled population as a starting value. \n\nSo, we approximate the probability of an individual having trait A with the relative frequency of trait A in the population: \n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\npopulation[\"trait\"].value_counts(normalize=True)[\"A\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n0.48\n```\n:::\n:::\n\n\nYou already know this code from above, we just added the `[\"A\"]` part at the end to select only the relative frequencies of trait A. We want to set this as the value of `p` of the first generation. This can be achieved with the `.loc` (location) method:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\noutput.loc[0, \"p\"] = population[\"trait\"].value_counts(normalize=True)[\"A\"]\n```\n:::\n\n\nIn words, this reads: \"Set location 0 (first row) in the `p` column of the `output` data frame to the relative frequency of the trait 'A' in the population.\"\n\n## Iterating over generations\n\nRecall that we are trying to observe cultural change over the course of `t_max = 100` generations. We thus simply repeat what we just did for the first generation: based on the relative frequencies of A's and B's in the previous generation, we sample the traits of 100 new individuals for the next generation.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfor t in range(1, t_max):\n    # Copy the population data frame to `previous_population`\n    previous_population = population.copy()\n  \n    # Randomly copy from previous generation's individuals\n    new_population = previous_population[\"trait\"].sample(N, replace=True).to_frame()\n    \n    # Get p and put it into the output slot for this generation t\n    output.loc[t, \"p\"] = new_population[ new_population[\"trait\"] == \"A\"].shape[0] / N\n```\n:::\n\n\nThis procedure assignes a probability of having trait \"A\" for each generation (each row of the `p` colum is filled now):\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\noutput.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=tex}\n\\begin{tabular}{lrr}\n\\toprule\n{} &  generation &     p \\\\\n\\midrule\n0 &           0 &  0.48 \\\\\n1 &           1 &  0.44 \\\\\n2 &           2 &  0.47 \\\\\n3 &           3 &  0.43 \\\\\n4 &           4 &  0.57 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nTo make things easier, we wrap the above code in a function that we'll call `unbiased_transmission` that can take different values for the population size `N` and number of generations `t_max` as parameters.\nThe code below is exactly the same as above.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndef unbiased_transmission_1(N, t_max):\n    population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)})\n\n    output = pd.DataFrame({\"generation\": np.arange(t_max, dtype=int), \"p\": [np.nan] * t_max })\n\n    output.loc[0, \"p\"] = population[ population[\"trait\"] == \"A\"].shape[0] / N\n\n    for t in range(1, t_max):\n        # Copy the population tibble to previous_population tibble\n        previous_population = population.copy()\n    \n        # Randomly copy from previous generation's individuals\n        new_population = previous_population[\"trait\"].sample(N, replace=True).to_frame()\n        \n        # Get p and put it into the output slot for this generation t\n        output.loc[t, \"p\"] = new_population[ new_population[\"trait\"] == \"A\"].shape[0] / N\n    \n    return output\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndata_model = unbiased_transmission_1(N=100, t_max=200)\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ndef plot_single_run(data_model):\n    data_model[\"p\"].plot(ylim=(0,1))\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nplot_single_run(data_model)\n```\n\n::: {.cell-output .cell-output-display}\n![Single run of the unbiased transmission model for a population of $N=100$ individuals and $t_{max}=200$ generations.](chapter03_files/figure-pdf/cell-18-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndata_model = unbiased_transmission_1(N=10_000, t_max=200)\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nplot_single_run(data_model)\n```\n\n::: {.cell-output .cell-output-display}\n![Single run of the unbiased transmission model for a population of $N=10,000$ individuals and $t_{max}=200$ generations.](chapter03_files/figure-pdf/cell-20-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n<!-- TODO: Implement interactive code as shiny app -->\n<!-- Try playing around with different parameter values. Bear in mind, however, that too large population sizes will take for ever to compute.\n\n```{shinylive-python}\n#| standalone: true\n#| viewerHeight: 420\n\nfrom shiny import App, render, ui\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nrng = np.random.default_rng()\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_slider(\"N\", \"population size\", 100, 10000, 1000, step=500),\n            ui.input_slider(\"t_max\", \"generations\", 1, 50, 20, step=1),\n        ),\n        ui.panel_main(\n            ui.output_plot(\"plot\"),\n        ),\n    ),\n)\n\ndef server(input, output, session):\n    @output\n    @render.plot(alt=\"First model\")\n    def plot():\n        plt.plot([1,2 * input.t_max() ], [3 + input.N(),4], marker=\"o\")\n        # def unbiased_transmission_1(N, t_max):\n        #     population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)}, index=[0])\n\n        #     output = pd.DataFrame({\"generation\": np.arange(t_max, dtype=int), \"p\": [np.nan] * t_max }, index=[0])\n\n        #     output.loc[0, \"p\"] = population[ population[\"trait\"] == \"A\"].shape[0] / N\n\n        #     for t in range(1, t_max):\n        #         # Copy the population tibble to previous_population tibble\n        #         previous_population = population.copy()\n            \n        #         # Randomly copy from previous generation's individuals\n        #         new_population = previous_population[\"trait\"].sample(N, replace=True).to_frame()\n                \n        #         # Get p and put it into the output slot for this generation t\n        #         output.loc[t, \"p\"] = new_population[ new_population[\"trait\"] == \"A\"].shape[0] / N\n            \n        #     return output\n        \n        # data_model = unbiased_transmission_1(N=None, t_max=None)\n\n        # def plot_single_run(data_model):\n        #     data_model[\"p\"].plot(ylim=(0,1))\n\n        # plot_single_run(data_model)\n\napp = App(app_ui, server)\n\n``` -->\n\nNow, let's adapt the code somewhat.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ndef unbiased_transmission_2(N, t_max, r_max):\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True)})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population.copy()\n\n            # Randomly compy from previous generation \n            population = population[\"trait\"].sample(N, replace=True).to_frame()\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nunbiased_transmission_2(100, 100, 3).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=tex}\n\\begin{tabular}{lrrr}\n\\toprule\n{} &  generation &     p &  run \\\\\n\\midrule\n0 &           0 &  0.45 &    0 \\\\\n1 &           1 &  0.38 &    0 \\\\\n2 &           2 &  0.35 &    0 \\\\\n3 &           3 &  0.40 &    0 \\\\\n4 &           4 &  0.41 &    0 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\n::: {.callout-tip}\nWhy could we append `.head()` to the `unbiased_transmission_2` function?\n:::\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ndata_model = unbiased_transmission_2(N=100, t_max=200, r_max=5)\n```\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndef plot_multiple_runs(data_model):\n    groups = data_model.groupby(\"run\")\n    for _, g in groups:\n        g.index = g[\"generation\"]\n        g[\"p\"].plot(lw=.5, ylim=(0,1))\n\n    data_model.groupby(\"generation\")[\"p\"].mean().plot(c=\"k\", lw=\"1\")\n```\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nplot_multiple_runs(data_model)\n```\n\n::: {.cell-output .cell-output-display}\n![Multiple runs of the unbiased transmission model for a population of $N=100$ individuals, with average (black line).](chapter03_files/figure-pdf/cell-25-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\ndata_model = unbiased_transmission_2(N=10_000, t_max=200, r_max=5)\n```\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nplot_multiple_runs(data_model)\n```\n\n::: {.cell-output .cell-output-display}\n![Multiple runs of the unbiased transmission model for a population of $N=10,000$ individuals, with average (black line).](chapter03_files/figure-pdf/cell-27-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\ndef unbiased_transmission_3(N, p_0, t_max, r_max):\n    output = pd.DataFrame({\n        \"generation\" : np.tile(np.arange(t_max), r_max),\n        \"p\" : [ np.nan ] * t_max * r_max,\n        \"run\" : np.repeat(np.arange(r_max), t_max)\n    })\n\n    for r in range(r_max):\n        # Create first generation\n        population = pd.DataFrame({\"trait\": rng.choice([\"A\", \"B\"], size=N, replace=True, p=[p_0, 1 - p_0])})\n\n        # Add first generation's p for run r\n        output.loc[ r * t_max, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n        # For each generation \n        for t in range(1,t_max):\n            # Copy individuals to previous_population DataFrame\n            previous_population = population\n\n            # Randomly compy from previous generation \n            population = population[\"trait\"].sample(N, replace=True).to_frame()\n\n            # Get p and put it into output slot for this generation t and run r\n            output.loc[r * t_max + t, \"p\"] = population[ population[\"trait\"] == \"A\" ].shape[0] / N\n\n    return output\n```\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\ndata_model = unbiased_transmission_3(10_000, p_0=.2, t_max=200, r_max=5)\nplot_multiple_runs(data_model)\n```\n\n::: {.cell-output .cell-output-display}\n![](chapter03_files/figure-pdf/cell-29-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n",
    "supporting": [
      "chapter03_files/figure-pdf"
    ],
    "filters": []
  }
}